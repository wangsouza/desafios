{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prova 02 B.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wangsouza/desafios/blob/main/Prova_02_B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsT1b0SYivaW"
      },
      "source": [
        "Utilizar visão computacional para identificar nos videos people-talking e people-walking pessoas falando e pessoas caminhando, \r\n",
        "gerando como saída um resultado similar aos vídeos people-talking-processed e people-walking-processed.\r\n",
        "\r\n",
        "Obs: Explique o que está sendo realizado em cada etapa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inQ4k4EhrxqX"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlxGW_GCkp7h"
      },
      "source": [
        "Para este desafio foi utilizado o classificador **Haar Cascade** para identificar rostos humanos e pessoas caminhando. O Haar cascade é uma abordagem eficaz de detecção de objetos proposta por Paul Viola e Michael Jones. Apesar de ter surgido em 2001, o seu desempenho tem evoluído com o passar dos anos. Atualmente, o Haar Cascade é bastante utilizados como base para sistemas mais avançados como reconhecimento facial, detector de fadiga, expressões faciais, e até mesmo detector de máscara facial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mmjohoPsEoN"
      },
      "source": [
        "1. Importa a biblioteca opencv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JudLqvljLsk"
      },
      "source": [
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXQBrMktsMlT"
      },
      "source": [
        "2. O desafio propõe a utilização de dois tipos de detectores (rostos e caminhada).\n",
        "O trecho de código abaixo permite que o usuário selecione apenas a **opção 1 (detector de rosto)** e **2 (detector de caminhada)**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kVTWFcRQWgB"
      },
      "source": [
        "while True:\n",
        "    try:\n",
        "        opt = int(input(\"Digite:\\n1. para acionar o detector de rostos.\\n2. para acionar o detector de caminhada.\\n\"))\n",
        "        if not 0 < opt <= 2:\n",
        "            raise ValueError(\"Digite apenas os valores 1 ou 2.\")\n",
        "    except ValueError as e:\n",
        "        print(\"Valor inválido:\", e)\n",
        "    else:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhfTgg5ItD8v"
      },
      "source": [
        "Caso o usuário opte pelo **detector de rostos**, ele digitará a opção 1 e os arquivos necessários para próxima etapa serão carregados. O processo será o mesmo caso ele opte pela opção 2.\n",
        "1. **CascadeClassifier** - Carrega o arquivo XML contendo os metadados de treinamento.\n",
        "2. **VideoCapture** - carrega o arquivo de entrada presente no disco. Para usar a webcam, basta trocar por 0, ou 1, caso a porta esteja ocupada.\n",
        "3. **fileNameOut** - nome do arquivo de saída (após o processamento)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iozl7dprRHo6"
      },
      "source": [
        "if opt == 1:\n",
        "  file_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
        "  cap = cv2.VideoCapture('people-talking.mp4')\n",
        "  fileNameOut = 'people-talking-processed.avi'\n",
        "else:\n",
        "  file_cascade = cv2.CascadeClassifier(\"haarcascade_fullbody.xml\")\n",
        "  cap = cv2.VideoCapture('people-walking.mp4')\n",
        "  fileNameOut = 'people-walking-processed.avi'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7G2LVmT8wMx"
      },
      "source": [
        "Para salvar o vídeo após o processamento, é preciso especificar o código fourCC de 4 bytes necessário para compactar o vídeo. Neste desafio foi utilizado o codec MP4V. A lista completa está disponível em [fourcc.org](http://www.fourcc.org/codecs.php)\n",
        "1. Resolução de saída\n",
        "2. Selecionar o codec (compactação do vídeo)\n",
        "3. Definir os parâmetros para salvar o vídeo como:\n",
        " * Nome do arquivo + extensão.\n",
        " * Codec.\n",
        " * Frames por segundo (FPS).\n",
        " * Resolução de saída.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ew_5yTYx9or_"
      },
      "source": [
        "res=(640,360)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "out = cv2.VideoWriter(fileNameOut, fourcc, 30.0, res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRLemqMTPsrD"
      },
      "source": [
        "Enquanto o vídeo estiver sendo executado, o laço While permanece como **True**.\n",
        "1. **ret, img = cap.read()** - A primeira variável (**ret**) indica um valor booleano, quando o vídeo ainda estiver sendo executado o seu valor é True. A variável **img** corresponde ao fluxo de vídeo. A função read() realiza a leitura do arquivo de vídeo.\n",
        "\n",
        "\n",
        "2. **if ret == False:break** - Ao chegar no fim da execução do vídeo a variável **ret** se torna False e a execução é imediatamente interrompida.\n",
        "\n",
        "3. O próximo passo é carregar a imagem e converter de RBG para escala de cinza. A razão para isso é que o canal cinza garante menos custo computacional, pois contém apenas 1 canal, em vez de 3 canais RBGs.\n",
        "     \n",
        "     **cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)**\n",
        " * **img** - fluxo de vídeo\n",
        " * **cv2.COLOR_BGR2GRAY** - É o código de conversão do espaço de cores.\n",
        "\n",
        "4. **file_cascade.detectMultiScale(gray, 1.1, 4)**\n",
        "Neste trecho de código, utilizamos o file_cascade contendo os metadados de treinamento e instanciamos ao método detectMultiScale. Este método ajudará localizar possíveis características a cada frame da imagem.\n",
        "Os parâmetros são:\n",
        " * **gray** - fluxo de vídeo em escala de cinza.\n",
        " * **scaleFactor** - parâmetro que especifica a escala que a imagem é reduzida. Ou seja, o modelo possui um tamanho definido durante o treinamento e está salvo no XML. Isso significa que se o objeto a ser detectado for maior que no arquivo XML, o fator de escala reduz o tamanho em 10%, baseado no valor 1.1, (5% no valor 1.05), e consequemente, aumentam as chances de coincidir com o modelo de detecção encontrado.\n",
        " * **minNeighbors** - especifica a quantidade de retângulos que serão retidos. Nessa fase, muitos falsos positivos poderão ocorrer, a função do minNeighbors é eliminar os falsos positivos. Valores maiores resultam em menos detecções.\n",
        "\n",
        "5. A função **detecMultiScale** retorna 4 valores, a coordenada x, coordenada y, largura (w) e altura (h) do objeto. Com base nesses 4 valores, será desenhado o retângulo.\n",
        "\n",
        " **cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 255), 2)**\n",
        " Os parâmetros são:\n",
        " * **img** - fluxo de vídeo com 3 canais (RGB)\n",
        " * **(x, y)** - a localização/coordenada do retângulo.\n",
        " * **(x + w, y + h)** - as dimensões do retângulo.\n",
        " * **(0, 255, 255)** - a cor da borda do retângulo.\n",
        " * **2** -  a espessura da linha.\n",
        "\n",
        "6. **out.write(img)** - a cada frame processado, as informações são gravadas no arquivo e compactadas com o codec previamente configurado.\n",
        "\n",
        "7. **out.release()** e **cap.release()** - Fecha os arquivos de vídeo e os liberam para outros processos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZw_dvNxjbFf"
      },
      "source": [
        "while True:\n",
        "  ret, img = cap.read()\n",
        "  if ret == False:\n",
        "    break\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  detections = file_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "  \n",
        "  for (x, y, w, h) in detections:\n",
        "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
        "  out.write(img)\n",
        "out.release()\n",
        "cap.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2J17wEx628O"
      },
      "source": [
        "É importante salientar que as configurações dos parâmetros scaleFactor, minNeighbors devem ser realizadas separadamente de forma empírica em cada projeto. Apesar de utilizarmos dois projetos no mesmo arquivo, o objetivo aqui foi economizar código. Pensando nisso, os parâmetros foram balanceados para que ambos tivessem os melhores desempenhos possíveis.\n"
      ]
    }
  ]
}